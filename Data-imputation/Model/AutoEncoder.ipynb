{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent = 14):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent = latent\n",
    "        # Encoder\n",
    "        #self.conv1 = nn.Conv1d(input_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, latent)\n",
    "        self.fc2 = nn.Linear(hidden_size , latent)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent, hidden_size)\n",
    "        #self.conv2 = nn.ConvTranspose1d(hidden_size, input_size, kernel_size=3, padding=1)\n",
    "        self.lstm2 = nn.LSTM(input_size=latent, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc4 = nn.Linear(hidden_size, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # x = torch.transpose(x, 1, 2)\n",
    "        # x = self.relu(self.conv1(x))\n",
    "        # x = torch.transpose(x, 1, 2)\n",
    "        x, (h,c) = self.lstm1(x)\n",
    "        #h = h.view(batch_size, -1)\n",
    "        mean = self.fc1(h)\n",
    "        logvar = self.fc2(h)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def decode(self, z, hidden):\n",
    "        # z = self.flatten(z)\n",
    "        # z = self.fc3(z)\n",
    "        # z = z.view(batch_size, lag_size, -1)\n",
    "        # z = torch.transpose(z, 1, 2)\n",
    "        # recon_x = self.conv2(z)\n",
    "        # recon_x = torch.transpose(recon_x, 1, 2)\n",
    "        recon_x, (_,_) = self.lstm2(z, hidden)\n",
    "        recon_x = self.fc4(recon_x)\n",
    "        # recon_x = self.relu(recon_x)\n",
    "        return recon_x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        h_ = self.fc3(z)\n",
    "        z = z.repeat(1, lag_size, 1)\n",
    "        z = z.view(batch_size, lag_size, self.latent)\n",
    "\n",
    "        # initialize hidden state\n",
    "        hidden = (h_.contiguous(), h_.contiguous())\n",
    "        recon_x = self.decode(z, hidden)\n",
    "        return recon_x, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
