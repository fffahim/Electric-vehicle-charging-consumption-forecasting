{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mogrifier_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, layer_size = 2):\n",
    "        super(Mogrifier_LSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.mogrifier_lstm_layer1 = MogrifierLSTMCell(input_size, hidden_size, layer_size)\n",
    "        self.mogrifier_lstm_layer2 = MogrifierLSTMCell(hidden_size, hidden_size, layer_size)\n",
    "\n",
    "        # Backward LSTM layer\n",
    "        self.mogrifier_lstm_layer1_backward = MogrifierLSTMCell(input_size, hidden_size, layer_size)\n",
    "        self.mogrifier_lstm_layer2_backward = MogrifierLSTMCell(hidden_size, hidden_size, layer_size)\n",
    "\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h1, c1 = [torch.zeros(self.batch_size, self.hidden_size).to(device), torch.zeros(self.batch_size, self.hidden_size).to(device)]\n",
    "        h2, c2 = [torch.zeros(self.batch_size, self.hidden_size).to(device), torch.zeros(self.batch_size, self.hidden_size).to(device)]\n",
    "        \n",
    "        h1_backward, c1_backward = torch.zeros(self.batch_size, self.hidden_size).to(device), torch.zeros(self.batch_size, self.hidden_size).to(device)\n",
    "        h2_backward, c2_backward = torch.zeros(self.batch_size, self.hidden_size).to(device), torch.zeros(self.batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        hidden_states_forward = []\n",
    "        hidden_states_backward = []\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(lag_size):\n",
    "            tempx = x[:, i]\n",
    "            h1,c1 = self.mogrifier_lstm_layer1(tempx, (h1, c1))     \n",
    "            #h2,c2 = self.mogrifier_lstm_layer2(h1, (h2, c2))\n",
    "            #out = self.linear1(h1)\n",
    "\n",
    "            hidden_states_forward.append(h1.unsqueeze(1))\n",
    "            #outputs.append(out.unsqueeze(1)) \n",
    "\n",
    "        # for i in reversed(range(x.size(1))):\n",
    "        #     tempx = x[:, i]\n",
    "        #     h1_backward, c1_backward = self.mogrifier_lstm_layer1_backward(tempx, (h1_backward, c1_backward))     \n",
    "        #     #h2_backward, c2_backward = self.mogrifier_lstm_layer2_backward(h1_backward, (h2_backward, c2_backward))\n",
    "        #     #out = self.linear1(h1_backward)\n",
    "        #     hidden_states_backward.append(h2.unsqueeze(1))\n",
    "        \n",
    "        hidden_states_forward = torch.cat(hidden_states_forward, dim=1)\n",
    "        # hidden_states_backward = torch.cat(hidden_states_backward, dim=1)\n",
    "\n",
    "        # Concatenate forward and backward hidden states\n",
    "        # hidden_states = torch.cat((hidden_states_forward, hidden_states_backward), dim=-1)\n",
    "        #hidden_states = torch.flatten(hidden_states[:, -1, :])\n",
    "        \n",
    "        outputs = self.linear(hidden_states_forward[:, -1, :])  # Only take the last time step output\n",
    "        #outputs = outputs.view(self.batch_size, -1)\n",
    "        # hidden_states = torch.cat(hidden_states, dim = 1)  \n",
    "        # outputs = torch.cat(outputs, dim = 1)  \n",
    "        # outputs = outputs[:, -1, :]     \n",
    "        \n",
    "        return self.relu(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MogrifierLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, mogrify_steps):\n",
    "        super(MogrifierLSTMCell, self).__init__()\n",
    "        self.mogrify_steps = mogrify_steps\n",
    "        self.lstm = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.mogrifier_list = nn.ModuleList([nn.Linear(hidden_size, input_size)])\n",
    "        for i in range(1, mogrify_steps):\n",
    "            if i % 2 == 0:\n",
    "                self.mogrifier_list.extend([nn.Linear(hidden_size, input_size)])\n",
    "            else:\n",
    "                self.mogrifier_list.extend([nn.Linear(input_size, hidden_size)])\n",
    "   \n",
    "    def mogrify(self, x, h):\n",
    "        for i in range(self.mogrify_steps):\n",
    "            if (i+1) % 2 == 0: \n",
    "                h = (2*torch.sigmoid(self.mogrifier_list[i](x))) * h\n",
    "            else:\n",
    "                x = (2*torch.sigmoid(self.mogrifier_list[i](h))) * x\n",
    "        return x, h\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        ht, ct = states\n",
    "        x, ht = self.mogrify(x, ht)\n",
    "        ht, ct = self.lstm(x, (ht, ct))\n",
    "        return ht, ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 10\n",
    "# hidden_size = 20\n",
    "# output_size = 1\n",
    "# batch_size = 3\n",
    "\n",
    "# # Create an instance of Mogrifier_LSTM\n",
    "# model = Mogrifier_LSTM(input_size, hidden_size, output_size, batch_size).to(device)\n",
    "\n",
    "# # Generate some dummy input data\n",
    "# sequence_length = 4\n",
    "# dummy_input = torch.randn(batch_size, sequence_length, input_size).to(device)\n",
    "\n",
    "# # Forward pass\n",
    "# output = model(dummy_input)\n",
    "\n",
    "# print(\"Output shape:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "torch.Size([4, 5])\n",
      "Output shape: torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class MogrifierLSTMCell(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, mogrify_steps):\n",
    "#         super(MogrifierLSTMCell, self).__init__()\n",
    "#         self.mogrify_steps = mogrify_steps\n",
    "#         self.lstm = nn.LSTMCell(input_size, hidden_size)\n",
    "#         self.mogrifier_list = nn.ModuleList([nn.Linear(hidden_size, input_size)])\n",
    "#         for i in range(1, mogrify_steps):\n",
    "#             if i % 2 == 0:\n",
    "#                 self.mogrifier_list.extend([nn.Linear(hidden_size, input_size)])\n",
    "#             else:\n",
    "#                 self.mogrifier_list.extend([nn.Linear(input_size, hidden_size)])\n",
    "   \n",
    "#     def mogrify(self, x, h):\n",
    "#         for i in range(self.mogrify_steps):\n",
    "#             if (i+1) % 2 == 0: \n",
    "#                 h = (2 * torch.sigmoid(self.mogrifier_list[i](x))) * h\n",
    "#             else:\n",
    "#                 x = (2 * torch.sigmoid(self.mogrifier_list[i](h))) * x\n",
    "#         return x, h\n",
    "\n",
    "#     def forward(self, x, states):\n",
    "#         ht, ct = states\n",
    "#         x, ht = self.mogrify(x, ht)\n",
    "#         ht, ct = self.lstm(x, (ht, ct))\n",
    "#         return ht, ct\n",
    "\n",
    "# # Define a simple Mogrifier LSTM model\n",
    "# class MogrifierLSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, mogrify_steps, output_size):\n",
    "#         super(MogrifierLSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.lstm_cell = MogrifierLSTMCell(input_size, hidden_size, mogrify_steps)\n",
    "#         self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#     def forward(self, input_seq):\n",
    "#         batch_size = input_seq.size(0)\n",
    "#         seq_len = input_seq.size(1)\n",
    "#         h = torch.zeros(batch_size, self.hidden_size, requires_grad=True)\n",
    "#         c = torch.zeros(batch_size, self.hidden_size, requires_grad=True)\n",
    "#         outputs = []\n",
    "\n",
    "#         for t in range(seq_len):\n",
    "#             h, c = self.lstm_cell(input_seq[:, t], (h, c))\n",
    "#             print(h.shape)\n",
    "#             outputs.append(h)\n",
    "            \n",
    "#         outputs = torch.stack(outputs, dim=1)\n",
    "#         outputs = self.linear(outputs)\n",
    "#         return outputs\n",
    "\n",
    "# # Example usage\n",
    "# input_size = 3\n",
    "# hidden_size = 5\n",
    "# mogrify_steps = 3\n",
    "# output_size = 3\n",
    "# batch_size = 4\n",
    "# seq_length = 2\n",
    "\n",
    "# model = MogrifierLSTM(input_size, hidden_size, mogrify_steps, output_size)\n",
    "# input_seq = torch.rand(batch_size, seq_length, input_size)  # Example input sequence\n",
    "# output_seq = model(input_seq)\n",
    "# print(\"Output shape:\", output_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
